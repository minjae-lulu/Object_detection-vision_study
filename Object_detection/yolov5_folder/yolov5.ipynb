{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov5.ipynb","provenance":[],"authorship_tag":"ABX9TyOfXvNgJlSAvpUR4vhhyCwK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kRcTgjnnRlmW"},"outputs":[],"source":["# download image dataset\n","!curl -L \"https://public.roboflow.ai/ds/WKkUorQ71T?key=wIBAdyawPa\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"]},{"cell_type":"code","source":["import torch\n","# check GPU is avaliable or not\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"metadata":{"id":"kEAIC2bx3Kj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# move to contetn and download yolov5 using git clone\n","%cd /content\n","!git clone https://github.com/ultralytics/yolov5.git"],"metadata":{"id":"fAZuGKh0SNsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# move to yolov5 and install reqired things using pip install \n","%cd /content/yolov5/\n","!pip install -r requirements.txt"],"metadata":{"id":"hS3L43aASN43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check yamlfile\n","# Í∑∏ÎÉ• Îã§Ïö¥ÌïòÎ©¥ dataset ÏóÜÎäîÎç∞, expertÌååÏùºÍ≥º yamlÌååÏùº ÎÑ£Ïñ¥Ï§¨Ïùå\n","%cat /content/dataset/data.yaml"],"metadata":{"id":"LM-9fDPESN-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /\n","from glob import glob\n","\n","img_list = glob('/content/dataset/export/images/*.jpg')\n","\n","print(len(img_list))"],"metadata":{"id":"n4esxgUtaGS-","executionInfo":{"status":"ok","timestamp":1660294881978,"user_tz":-540,"elapsed":555,"user":{"displayName":"Ïù¥ÎØºÏû¨","userId":"00823326776147256347"}},"outputId":"12276cc0-3591-4dd4-f3b6-33268fd2896b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/\n","2971\n"]}]},{"cell_type":"code","source":["# divide test set and train set\n","from sklearn.model_selection import train_test_split\n","\n","train_img_list, val_img_list = train_test_split(img_list, test_size=0.2, random_state=2000)\n","\n","print(len(train_img_list), len(val_img_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIW_sabp3Md7","executionInfo":{"status":"ok","timestamp":1660294888830,"user_tz":-540,"elapsed":551,"user":{"displayName":"Ïù¥ÎØºÏû¨","userId":"00823326776147256347"}},"outputId":"351a993c-b8eb-4095-a5b7-2743a30e321c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2376 595\n"]}]},{"cell_type":"code","source":["#save image load txt file\n","# make train.txt and val.txt at dataset folder\n","with open('/content/dataset/train.txt', 'w') as f:\n","  f.write('\\n'.join(train_img_list) + '\\n')\n","\n","with open('/content/dataset/val.txt', 'w') as f:\n","  f.write('\\n'.join(val_img_list) + '\\n')"],"metadata":{"id":"I-oSBzi53Mgw","executionInfo":{"status":"ok","timestamp":1660294892669,"user_tz":-540,"elapsed":548,"user":{"displayName":"Ïù¥ÎØºÏû¨","userId":"00823326776147256347"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#use yaml.safe_load() instead of yaml.load (version upgraded) \n","# modify .yaml file train: ???? val : ????                     ???? changed\n","import yaml\n","\n","with open('/content/dataset/data.yaml', 'r') as f:\n","  data = yaml.safe_load(f)\n","\n","print(data)\n","\n","data['train'] = '/content/dataset/train.txt'\n","data['val'] = '/content/dataset/val.txt'\n","\n","with open('/content/dataset/data.yaml', 'w') as f:\n","  yaml.dump(data, f)\n","\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBd2E-T-3nLP","executionInfo":{"status":"ok","timestamp":1660294899540,"user_tz":-540,"elapsed":543,"user":{"displayName":"Ïù¥ÎØºÏû¨","userId":"00823326776147256347"}},"outputId":"f2731746-e4dc-4d9d-de3e-167ba15b9fca"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["{'train': '../train/images', 'val': '../valid/images', 'nc': 1, 'names': ['pistol']}\n","{'train': '/content/dataset/train.txt', 'val': '/content/dataset/val.txt', 'nc': 1, 'names': ['pistol']}\n"]}]},{"cell_type":"code","source":["# change directory and train epochs 5 batch 16\n","# training using yolov5s\n","%cd /content/yolov5/\n","\n","!python train.py --img 416 --batch 16 --epochs 5 --data /content/dataset/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name gun_yolov5s_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vwREMIO3nNk","executionInfo":{"status":"ok","timestamp":1660295187648,"user_tz":-540,"elapsed":277122,"user":{"displayName":"Ïù¥ÎØºÏû¨","userId":"00823326776147256347"}},"outputId":"14b7d2a2-9fbe-4c9f-d122-3652e55a45ee"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/yolov5s.yaml, data=/content/dataset/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=gun_yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n","YOLOv5 üöÄ v6.1-386-g2e57b84 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs in Weights & Biases\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ runs in ClearML\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 140MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 275MB/s]\n","\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n","\n","Transferred 342/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/dataset/train' images and labels...2376 found, 0 missing, 0 empty, 0 corrupt: 100% 2376/2376 [00:01<00:00, 2189.77it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/dataset/val' images and labels...595 found, 0 missing, 0 empty, 0 corrupt: 100% 595/595 [00:00<00:00, 1085.76it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/val.cache\n","Plotting labels to runs/train/gun_yolov5s_results/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.92 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/gun_yolov5s_results\u001b[0m\n","Starting training for 5 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/4     1.71G   0.08702   0.02182         0        28       416: 100% 149/149 [00:43<00:00,  3.41it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:06<00:00,  2.99it/s]\n","                 all        595        681      0.662      0.493      0.584      0.343\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/4     2.07G   0.05541   0.02082         0        32       416: 100% 149/149 [00:40<00:00,  3.71it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:05<00:00,  3.78it/s]\n","                 all        595        681      0.772      0.612      0.733      0.429\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/4     2.07G    0.0473   0.01828         0        21       416: 100% 149/149 [00:38<00:00,  3.92it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:05<00:00,  3.75it/s]\n","                 all        595        681      0.808      0.748      0.816      0.499\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/4     2.07G   0.04161   0.01746         0        19       416: 100% 149/149 [00:38<00:00,  3.89it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:04<00:00,  3.81it/s]\n","                 all        595        681      0.824      0.789      0.856      0.546\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/4     2.07G   0.03953   0.01636         0        14       416: 100% 149/149 [00:44<00:00,  3.33it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:04<00:00,  3.88it/s]\n","                 all        595        681      0.866      0.775      0.866      0.599\n","\n","5 epochs completed in 0.065 hours.\n","Optimizer stripped from runs/train/gun_yolov5s_results/weights/last.pt, 14.3MB\n","Optimizer stripped from runs/train/gun_yolov5s_results/weights/best.pt, 14.3MB\n","\n","Validating runs/train/gun_yolov5s_results/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:06<00:00,  2.94it/s]\n","                 all        595        681      0.867      0.774      0.867        0.6\n","Results saved to \u001b[1mruns/train/gun_yolov5s_results\u001b[0m\n"]}]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir /content/yolov5/runs/"],"metadata":{"id":"9auqW_Ru3nUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image\n","import os\n","\n","val_img_path = val_img_list[6]\n","\n","# inference (image path, and variable)\n","#!python detect.py --weights /content/yolov5/runs/exp0_gun_yolov5s_results/weights/best_gun_yolov5s_results.pt --img 416 --conf 0.5 --source \"{val_img_path}\"\n","!python detect.py --weights /content/yolov5/runs/train/gun_yolov5s_results/weights/best.pt/ --img 416 --conf 0.5 --source \"{val_img_path}\"\n","\n","#Image(os.path.join('/content/yolov5/runs/detect/exp2/output', os.path.basename(val_img_path)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nACZEgazB1mG","executionInfo":{"status":"ok","timestamp":1660295850450,"user_tz":-540,"elapsed":7089,"user":{"displayName":"Ïù¥ÎØºÏû¨","userId":"00823326776147256347"}},"outputId":"93b84472-fb02-44ba-b8d8-33f13970fd16"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/gun_yolov5s_results/weights/best.pt/'], source=/content/dataset/export/images/armas (450)_jpg.rf.dfa92944dce4b4c9e5359037de072598.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","YOLOv5 üöÄ v6.1-386-g2e57b84 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/1 /content/dataset/export/images/armas (450)_jpg.rf.dfa92944dce4b4c9e5359037de072598.jpg: 416x416 Done. (0.008s)\n","Speed: 0.4ms pre-process, 8.1ms inference, 0.4ms NMS per image at shape (1, 3, 416, 416)\n","Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n"]}]},{"cell_type":"code","source":["Image(os.path.join('/content/yolov5/runs/detect/exp2/1.jpg', os.path.basename(val_img_path)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"PSZsUV3RVuT4","executionInfo":{"status":"ok","timestamp":1660295829223,"user_tz":-540,"elapsed":4,"user":{"displayName":"Ïù¥ÎØºÏû¨","userId":"00823326776147256347"}},"outputId":"faccfa51-7f38-4551-eef0-88f0518d0903"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Image object>"],"image/png":"/content/yolov5/runs/detect/exp2/1.jpg/armas (2074)_jpg.rf.915fdbc0c173fb421a68931b4c2df574.jpg"},"metadata":{},"execution_count":22}]}]}